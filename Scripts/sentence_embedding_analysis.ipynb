{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:21:49.137425200Z",
     "start_time": "2023-10-25T20:21:42.282262100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1         2         3         4         5         6  \\\n0  0.285478 -0.267780  0.419370 -0.498186  0.542660  0.023841 -0.413265   \n1  0.005152 -0.338731  0.156136 -0.549878  0.695794  0.311146 -0.125933   \n2  0.116819 -0.197075  0.522070 -0.512381  0.799792  0.214954 -0.282300   \n3  0.064937 -0.105588  0.331254 -0.469864  0.336095  0.206220 -0.359127   \n4  0.100418 -0.234218  0.355078 -0.581577  0.777377  0.154805 -0.313815   \n\n          7         8         9  ...       759       760       761       762  \\\n0 -0.031106  0.037016 -0.089733  ...  0.053731 -0.071965 -0.196012 -0.272531   \n1 -0.057170 -0.142586 -0.237876  ...  0.050056 -0.013978 -0.242019 -0.162937   \n2  0.112953 -0.276646 -0.476294  ... -0.097296 -0.053955 -0.135379 -0.325609   \n3 -0.268113  0.054264 -0.154883  ...  0.032132 -0.176046 -0.018010 -0.372751   \n4  0.036311 -0.163821 -0.168941  ... -0.000433 -0.007743 -0.323721 -0.179224   \n\n        763       764       765       766       767                Track_ID  \n0 -0.218975  0.226477 -0.190769  0.270417 -0.245182  3oqWr0jDWNXxWufNogGREp  \n1 -0.217069  0.228585 -0.211428  0.152560 -0.290909  6gwaa6ElIixNTvu6RwkMyo  \n2 -0.221731  0.388578  0.004549  0.260015 -0.495187  1rh4kDY9T4fHVDum8Foi5k  \n3 -0.036383  0.301428 -0.064544  0.210582 -0.569920  12uaDRCVrgu4O6AyOZLrxG  \n4 -0.251005  0.338842 -0.198423  0.395761 -0.336876  17eJyYLIlMNlOqcwHYJ9F2  \n\n[5 rows x 769 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>759</th>\n      <th>760</th>\n      <th>761</th>\n      <th>762</th>\n      <th>763</th>\n      <th>764</th>\n      <th>765</th>\n      <th>766</th>\n      <th>767</th>\n      <th>Track_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.285478</td>\n      <td>-0.267780</td>\n      <td>0.419370</td>\n      <td>-0.498186</td>\n      <td>0.542660</td>\n      <td>0.023841</td>\n      <td>-0.413265</td>\n      <td>-0.031106</td>\n      <td>0.037016</td>\n      <td>-0.089733</td>\n      <td>...</td>\n      <td>0.053731</td>\n      <td>-0.071965</td>\n      <td>-0.196012</td>\n      <td>-0.272531</td>\n      <td>-0.218975</td>\n      <td>0.226477</td>\n      <td>-0.190769</td>\n      <td>0.270417</td>\n      <td>-0.245182</td>\n      <td>3oqWr0jDWNXxWufNogGREp</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.005152</td>\n      <td>-0.338731</td>\n      <td>0.156136</td>\n      <td>-0.549878</td>\n      <td>0.695794</td>\n      <td>0.311146</td>\n      <td>-0.125933</td>\n      <td>-0.057170</td>\n      <td>-0.142586</td>\n      <td>-0.237876</td>\n      <td>...</td>\n      <td>0.050056</td>\n      <td>-0.013978</td>\n      <td>-0.242019</td>\n      <td>-0.162937</td>\n      <td>-0.217069</td>\n      <td>0.228585</td>\n      <td>-0.211428</td>\n      <td>0.152560</td>\n      <td>-0.290909</td>\n      <td>6gwaa6ElIixNTvu6RwkMyo</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.116819</td>\n      <td>-0.197075</td>\n      <td>0.522070</td>\n      <td>-0.512381</td>\n      <td>0.799792</td>\n      <td>0.214954</td>\n      <td>-0.282300</td>\n      <td>0.112953</td>\n      <td>-0.276646</td>\n      <td>-0.476294</td>\n      <td>...</td>\n      <td>-0.097296</td>\n      <td>-0.053955</td>\n      <td>-0.135379</td>\n      <td>-0.325609</td>\n      <td>-0.221731</td>\n      <td>0.388578</td>\n      <td>0.004549</td>\n      <td>0.260015</td>\n      <td>-0.495187</td>\n      <td>1rh4kDY9T4fHVDum8Foi5k</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.064937</td>\n      <td>-0.105588</td>\n      <td>0.331254</td>\n      <td>-0.469864</td>\n      <td>0.336095</td>\n      <td>0.206220</td>\n      <td>-0.359127</td>\n      <td>-0.268113</td>\n      <td>0.054264</td>\n      <td>-0.154883</td>\n      <td>...</td>\n      <td>0.032132</td>\n      <td>-0.176046</td>\n      <td>-0.018010</td>\n      <td>-0.372751</td>\n      <td>-0.036383</td>\n      <td>0.301428</td>\n      <td>-0.064544</td>\n      <td>0.210582</td>\n      <td>-0.569920</td>\n      <td>12uaDRCVrgu4O6AyOZLrxG</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.100418</td>\n      <td>-0.234218</td>\n      <td>0.355078</td>\n      <td>-0.581577</td>\n      <td>0.777377</td>\n      <td>0.154805</td>\n      <td>-0.313815</td>\n      <td>0.036311</td>\n      <td>-0.163821</td>\n      <td>-0.168941</td>\n      <td>...</td>\n      <td>-0.000433</td>\n      <td>-0.007743</td>\n      <td>-0.323721</td>\n      <td>-0.179224</td>\n      <td>-0.251005</td>\n      <td>0.338842</td>\n      <td>-0.198423</td>\n      <td>0.395761</td>\n      <td>-0.336876</td>\n      <td>17eJyYLIlMNlOqcwHYJ9F2</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 769 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "## Cargo los embeddings\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "parquet_file_path = r'C:\\Users\\nunez\\Facultad\\Factor Data\\Embeddings\\clean_rock_nacional_w_embeddings.parquet'\n",
    "\n",
    "columns_to_load = [\"sentence_embeddings\", \"Track_ID\"]\n",
    "table = pq.read_table(parquet_file_path, columns=columns_to_load)\n",
    "df = table.to_pandas()\n",
    "del table\n",
    "df_1 = pd.DataFrame(df['sentence_embeddings'].to_list())\n",
    "df_2 = df[\"Track_ID\"]\n",
    "del df\n",
    "\n",
    "df = pd.concat([df_1, df_2], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aplico dimensionality reduction a los embeddings\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "pca = PCA(n_components=3)\n",
    "reduced_embeddings = pca.fit_transform(df.drop(columns=[\"Track_ID\"]))\n",
    "reduced_embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 2], reduced_embeddings[:, 1])\n",
    "\n",
    "ax.set_xlabel('PCA 1')\n",
    "ax.set_ylabel('PCA 2')\n",
    "ax.set_zlabel('PCA 3')\n",
    "plt.title('3D Scatter Plot Embeddings')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nunez\\Work\\DataSpell\\Venvs\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Cluster_Labels                Track_ID\n0                  3  3oqWr0jDWNXxWufNogGREp\n1                  3  6gwaa6ElIixNTvu6RwkMyo\n2                  5  1rh4kDY9T4fHVDum8Foi5k\n3                  3  12uaDRCVrgu4O6AyOZLrxG\n4                  3  17eJyYLIlMNlOqcwHYJ9F2\n...              ...                     ...\n2360               3  2MoFgRCvQMBy6cgw55oQvV\n2361               7  2axmxXWKBu2zEa1d8hrQVD\n2362               1  49bT0U3Ug059MXsBYrUWda\n2363               1  6RcII8epzXd254KF82RhAp\n2364               1  2A4A4iW4B3yoxkrgfXqtec\n\n[2365 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cluster_Labels</th>\n      <th>Track_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>3oqWr0jDWNXxWufNogGREp</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>6gwaa6ElIixNTvu6RwkMyo</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>1rh4kDY9T4fHVDum8Foi5k</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>12uaDRCVrgu4O6AyOZLrxG</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>17eJyYLIlMNlOqcwHYJ9F2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2360</th>\n      <td>3</td>\n      <td>2MoFgRCvQMBy6cgw55oQvV</td>\n    </tr>\n    <tr>\n      <th>2361</th>\n      <td>7</td>\n      <td>2axmxXWKBu2zEa1d8hrQVD</td>\n    </tr>\n    <tr>\n      <th>2362</th>\n      <td>1</td>\n      <td>49bT0U3Ug059MXsBYrUWda</td>\n    </tr>\n    <tr>\n      <th>2363</th>\n      <td>1</td>\n      <td>6RcII8epzXd254KF82RhAp</td>\n    </tr>\n    <tr>\n      <th>2364</th>\n      <td>1</td>\n      <td>2A4A4iW4B3yoxkrgfXqtec</td>\n    </tr>\n  </tbody>\n</table>\n<p>2365 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 8\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(df.drop(columns=[\"Track_ID\"]))\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "df = pd.concat([pd.Series(cluster_labels, name='Cluster_Labels'), df[\"Track_ID\"]],\n",
    "             axis=1)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:21:50.317425800Z",
     "start_time": "2023-10-25T20:21:49.136424500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "# Create a 3D scatter plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Iterate through clusters and plot data points with corresponding colors\n",
    "for cluster_label in df['Cluster_Labels'].unique():\n",
    "    mask = df[df[\"Cluster_Labels\"] == cluster_label]\n",
    "    ax.scatter(mask[0], mask[2], mask[1], label=f'Cluster {cluster_label}', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "plt.title('3D Scatter Plot of Embeddings with Cluster Colors')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "      Cluster_Labels                Track_ID  Unnamed: 0          Artist  \\\n0                  3  3oqWr0jDWNXxWufNogGREp           0  Gustavo Cerati   \n1                  3  6gwaa6ElIixNTvu6RwkMyo           0  Gustavo Cerati   \n2                  5  1rh4kDY9T4fHVDum8Foi5k           0  Gustavo Cerati   \n3                  3  12uaDRCVrgu4O6AyOZLrxG           0  Gustavo Cerati   \n4                  3  17eJyYLIlMNlOqcwHYJ9F2           0  Gustavo Cerati   \n...              ...                     ...         ...             ...   \n2496               3  2MoFgRCvQMBy6cgw55oQvV          86     Dread Mar I   \n2497               7  2axmxXWKBu2zEa1d8hrQVD          86     Dread Mar I   \n2498               1  49bT0U3Ug059MXsBYrUWda          86     Dread Mar I   \n2499               1  6RcII8epzXd254KF82RhAp          86     Dread Mar I   \n2500               1  2A4A4iW4B3yoxkrgfXqtec          86     Dread Mar I   \n\n                   Artist_ID  \\\n0     1QOmebWGB6FdFtW7Bo3F0W   \n1     1QOmebWGB6FdFtW7Bo3F0W   \n2     1QOmebWGB6FdFtW7Bo3F0W   \n3     1QOmebWGB6FdFtW7Bo3F0W   \n4     1QOmebWGB6FdFtW7Bo3F0W   \n...                      ...   \n2496  1aw0Cdl1DIrtUrUA6fGbAR   \n2497  1aw0Cdl1DIrtUrUA6fGbAR   \n2498  1aw0Cdl1DIrtUrUA6fGbAR   \n2499  1aw0Cdl1DIrtUrUA6fGbAR   \n2500  1aw0Cdl1DIrtUrUA6fGbAR   \n\n                                          Artist_genres  Artist_popularity  \\\n0     ['argentine rock', 'latin alternative', 'latin...                 70   \n1     ['argentine rock', 'latin alternative', 'latin...                 70   \n2     ['argentine rock', 'latin alternative', 'latin...                 70   \n3     ['argentine rock', 'latin alternative', 'latin...                 70   \n4     ['argentine rock', 'latin alternative', 'latin...                 70   \n...                                                 ...                ...   \n2496  ['argentine reggae', 'latin alternative', 'roc...                 69   \n2497  ['argentine reggae', 'latin alternative', 'roc...                 69   \n2498  ['argentine reggae', 'latin alternative', 'roc...                 69   \n2499  ['argentine reggae', 'latin alternative', 'roc...                 69   \n2500  ['argentine reggae', 'latin alternative', 'roc...                 69   \n\n                    Track Track_release_date  Track_popularity  \\\n0                  Crimen         2006-04-04              75.0   \n1                  Puente         1999-06-01              71.0   \n2                   AdiÃ³s         2006-04-04              73.0   \n3                Bocanada         1999-06-01              64.0   \n4        Lago en el Cielo         2006-04-04              68.0   \n...                   ...                ...               ...   \n2496           Tu Soldado         2012-11-01              48.0   \n2497            La Suerte         2018-05-18              48.0   \n2498    SÃ¡lvame - En Vivo         2016-05-06              47.0   \n2499  Tu Sin Mi - En Vivo         2016-05-06              45.0   \n2500    Mi Amor - En Vivo         2016-05-06              46.0   \n\n                                                 Lyrics  \\\n0        la espera me agotÃ³ no sÃ© nada de vos dejast...   \n1        hoy te busquÃ© en la rima que duerme con tod...   \n2        suspiraban lo mismo los dos y hoy son parte...   \n3        cuando no hay mÃ¡s que decirnos habla el hum...   \n4        un lago en el cielo quiero ser suave para e...   \n...                                                 ...   \n2496    oh sÃ­ hoy me quieren convencer para que caig...   \n2497  letra de la suerte   la suerte que tÃº creas na...   \n2498   lyrics te convertÃ­ en una reina pa cualquier ...   \n2499     yeah yeah yeah vine a romper un beat que pu...   \n2500     me gustas tÃº me gusta la lluvia me gustas t...   \n\n                                          features_dict  \n0                                                   NaN  \n1                                                   NaN  \n2     {'danceability': 0.495, 'energy': 0.596, 'key'...  \n3     {'danceability': 0.47, 'energy': 0.575, 'key':...  \n4     {'danceability': 0.539, 'energy': 0.833, 'key'...  \n...                                                 ...  \n2496  {'danceability': 0.699, 'energy': 0.271, 'key'...  \n2497  {'danceability': 0.687, 'energy': 0.614, 'key'...  \n2498  {'danceability': 0.562, 'energy': 0.742, 'key'...  \n2499  {'danceability': 0.578, 'energy': 0.689, 'key'...  \n2500  {'danceability': 0.372, 'energy': 0.672, 'key'...  \n\n[2265 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cluster_Labels</th>\n      <th>Track_ID</th>\n      <th>Unnamed: 0</th>\n      <th>Artist</th>\n      <th>Artist_ID</th>\n      <th>Artist_genres</th>\n      <th>Artist_popularity</th>\n      <th>Track</th>\n      <th>Track_release_date</th>\n      <th>Track_popularity</th>\n      <th>Lyrics</th>\n      <th>features_dict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>3oqWr0jDWNXxWufNogGREp</td>\n      <td>0</td>\n      <td>Gustavo Cerati</td>\n      <td>1QOmebWGB6FdFtW7Bo3F0W</td>\n      <td>['argentine rock', 'latin alternative', 'latin...</td>\n      <td>70</td>\n      <td>Crimen</td>\n      <td>2006-04-04</td>\n      <td>75.0</td>\n      <td>la espera me agotÃ³ no sÃ© nada de vos dejast...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>6gwaa6ElIixNTvu6RwkMyo</td>\n      <td>0</td>\n      <td>Gustavo Cerati</td>\n      <td>1QOmebWGB6FdFtW7Bo3F0W</td>\n      <td>['argentine rock', 'latin alternative', 'latin...</td>\n      <td>70</td>\n      <td>Puente</td>\n      <td>1999-06-01</td>\n      <td>71.0</td>\n      <td>hoy te busquÃ© en la rima que duerme con tod...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>1rh4kDY9T4fHVDum8Foi5k</td>\n      <td>0</td>\n      <td>Gustavo Cerati</td>\n      <td>1QOmebWGB6FdFtW7Bo3F0W</td>\n      <td>['argentine rock', 'latin alternative', 'latin...</td>\n      <td>70</td>\n      <td>AdiÃ³s</td>\n      <td>2006-04-04</td>\n      <td>73.0</td>\n      <td>suspiraban lo mismo los dos y hoy son parte...</td>\n      <td>{'danceability': 0.495, 'energy': 0.596, 'key'...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>12uaDRCVrgu4O6AyOZLrxG</td>\n      <td>0</td>\n      <td>Gustavo Cerati</td>\n      <td>1QOmebWGB6FdFtW7Bo3F0W</td>\n      <td>['argentine rock', 'latin alternative', 'latin...</td>\n      <td>70</td>\n      <td>Bocanada</td>\n      <td>1999-06-01</td>\n      <td>64.0</td>\n      <td>cuando no hay mÃ¡s que decirnos habla el hum...</td>\n      <td>{'danceability': 0.47, 'energy': 0.575, 'key':...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>17eJyYLIlMNlOqcwHYJ9F2</td>\n      <td>0</td>\n      <td>Gustavo Cerati</td>\n      <td>1QOmebWGB6FdFtW7Bo3F0W</td>\n      <td>['argentine rock', 'latin alternative', 'latin...</td>\n      <td>70</td>\n      <td>Lago en el Cielo</td>\n      <td>2006-04-04</td>\n      <td>68.0</td>\n      <td>un lago en el cielo quiero ser suave para e...</td>\n      <td>{'danceability': 0.539, 'energy': 0.833, 'key'...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2496</th>\n      <td>3</td>\n      <td>2MoFgRCvQMBy6cgw55oQvV</td>\n      <td>86</td>\n      <td>Dread Mar I</td>\n      <td>1aw0Cdl1DIrtUrUA6fGbAR</td>\n      <td>['argentine reggae', 'latin alternative', 'roc...</td>\n      <td>69</td>\n      <td>Tu Soldado</td>\n      <td>2012-11-01</td>\n      <td>48.0</td>\n      <td>oh sÃ­ hoy me quieren convencer para que caig...</td>\n      <td>{'danceability': 0.699, 'energy': 0.271, 'key'...</td>\n    </tr>\n    <tr>\n      <th>2497</th>\n      <td>7</td>\n      <td>2axmxXWKBu2zEa1d8hrQVD</td>\n      <td>86</td>\n      <td>Dread Mar I</td>\n      <td>1aw0Cdl1DIrtUrUA6fGbAR</td>\n      <td>['argentine reggae', 'latin alternative', 'roc...</td>\n      <td>69</td>\n      <td>La Suerte</td>\n      <td>2018-05-18</td>\n      <td>48.0</td>\n      <td>letra de la suerte   la suerte que tÃº creas na...</td>\n      <td>{'danceability': 0.687, 'energy': 0.614, 'key'...</td>\n    </tr>\n    <tr>\n      <th>2498</th>\n      <td>1</td>\n      <td>49bT0U3Ug059MXsBYrUWda</td>\n      <td>86</td>\n      <td>Dread Mar I</td>\n      <td>1aw0Cdl1DIrtUrUA6fGbAR</td>\n      <td>['argentine reggae', 'latin alternative', 'roc...</td>\n      <td>69</td>\n      <td>SÃ¡lvame - En Vivo</td>\n      <td>2016-05-06</td>\n      <td>47.0</td>\n      <td>lyrics te convertÃ­ en una reina pa cualquier ...</td>\n      <td>{'danceability': 0.562, 'energy': 0.742, 'key'...</td>\n    </tr>\n    <tr>\n      <th>2499</th>\n      <td>1</td>\n      <td>6RcII8epzXd254KF82RhAp</td>\n      <td>86</td>\n      <td>Dread Mar I</td>\n      <td>1aw0Cdl1DIrtUrUA6fGbAR</td>\n      <td>['argentine reggae', 'latin alternative', 'roc...</td>\n      <td>69</td>\n      <td>Tu Sin Mi - En Vivo</td>\n      <td>2016-05-06</td>\n      <td>45.0</td>\n      <td>yeah yeah yeah vine a romper un beat que pu...</td>\n      <td>{'danceability': 0.578, 'energy': 0.689, 'key'...</td>\n    </tr>\n    <tr>\n      <th>2500</th>\n      <td>1</td>\n      <td>2A4A4iW4B3yoxkrgfXqtec</td>\n      <td>86</td>\n      <td>Dread Mar I</td>\n      <td>1aw0Cdl1DIrtUrUA6fGbAR</td>\n      <td>['argentine reggae', 'latin alternative', 'roc...</td>\n      <td>69</td>\n      <td>Mi Amor - En Vivo</td>\n      <td>2016-05-06</td>\n      <td>46.0</td>\n      <td>me gustas tÃº me gusta la lluvia me gustas t...</td>\n      <td>{'danceability': 0.372, 'energy': 0.672, 'key'...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2265 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "df1 = pd.read_csv(r\"C:\\Users\\nunez\\Facultad\\Factor Data\\Proyecto NLP canciones\\Datasets Scrapeados\\Rock_Nacional.csv\")\n",
    "df = pd.merge(df,df1,on=\"Track_ID\")\n",
    "df\n",
    "\n",
    "\n",
    "## Cleansing\n",
    "df.dropna(subset=\"Lyrics\",inplace=True)\n",
    "def clean(text):\n",
    "    cleaned_text = re.sub(r\"^.*?Lyrics\", \"\", text)\n",
    "    cleaned_text = re.sub(r'\\[.*?\\]', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\([^)]*\\)', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\\\n', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\n', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'Embed', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'you might also like', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'you', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'might', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'also', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'like', '', cleaned_text)\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return cleaned_text\n",
    "\n",
    "df[\"Lyrics\"] = df[\"Lyrics\"].astype(str).apply(clean)\n",
    "df[\"Artist_genres\"] = df[\"Artist_genres\"].replace(\"[]\",np.nan)\n",
    "df.dropna(subset=\"Artist_genres\",inplace=True)\n",
    "df = df.drop_duplicates(subset=[\"Lyrics\",\"Artist_ID\",\"Track\"])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:21:51.826426Z",
     "start_time": "2023-10-25T20:21:50.321424400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = df.groupby(\"Cluster_Labels\")[\"Lyrics\"].apply(lambda x: ' '.join(x)).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:21:51.842425200Z",
     "start_time": "2023-10-25T20:21:51.828425900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   Cluster_Labels                                             Lyrics\n0               0     un cactus suaviza mis yemas con su piel tie...\n1               1  en la maÃ±ana desayuno las dudas que sobran de ...\n2               2     ya no me necesitas es lo mejor eras alguien...\n3               3     la espera me agotÃ³ no sÃ© nada de vos dejast...\n4               4  os sertÃµes de euclides da cunha fonte cunha eu...\n5               5     suspiraban lo mismo los dos y hoy son parte...\n6               6   erasmo de rotterda lyricsenquiridion o manual...\n7               7  no me arrepiento de este amor aunque me cueste...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cluster_Labels</th>\n      <th>Lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>un cactus suaviza mis yemas con su piel tie...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>en la maÃ±ana desayuno las dudas que sobran de ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>ya no me necesitas es lo mejor eras alguien...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>la espera me agotÃ³ no sÃ© nada de vos dejast...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>os sertÃµes de euclides da cunha fonte cunha eu...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>suspiraban lo mismo los dos y hoy son parte...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>erasmo de rotterda lyricsenquiridion o manual...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>no me arrepiento de este amor aunque me cueste...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:21:51.978426400Z",
     "start_time": "2023-10-25T20:21:51.842425200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download necessary NLTK resources if you haven't already\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load Spanish stopwords\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "# Define the function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    words = nltk.word_tokenize(text, language='spanish')\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "\n",
    "# Assuming df is your DataFrame and \"Lyrics\" is the column containing text data\n",
    "df[\"Lyrics\"] = df[\"Lyrics\"].apply(remove_stopwords)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:22:00.431182400Z",
     "start_time": "2023-10-25T20:21:51.942424800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   Cluster_Labels                                             Lyrics\n0               0  cactus suaviza yemas piel cien aÃ±os solo flore...\n1               1  maÃ±ana desayuno dudas sobran noche anterior lu...\n2               2  necesitas mejor alguien quiÃ©n solÃ­a conocer si...\n3               3  espera agotÃ³ sÃ© vos dejaste llamas acostÃ© lent...\n4               4  sertÃµes euclides da cunha fonte cunha euclides...\n5               5  suspiraban mismo dos hoy parte lluvia lejos co...\n6               6  erasmo rotterda lyricsenquiridion manual cabal...\n7               7  arrepiento amor aunque cueste corazÃ³n amar mil...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cluster_Labels</th>\n      <th>Lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>cactus suaviza yemas piel cien aÃ±os solo flore...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>maÃ±ana desayuno dudas sobran noche anterior lu...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>necesitas mejor alguien quiÃ©n solÃ­a conocer si...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>espera agotÃ³ sÃ© vos dejaste llamas acostÃ© lent...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>sertÃµes euclides da cunha fonte cunha euclides...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>suspiraban mismo dos hoy parte lluvia lejos co...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>erasmo rotterda lyricsenquiridion manual cabal...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>arrepiento amor aunque cueste corazÃ³n amar mil...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:22:00.479183400Z",
     "start_time": "2023-10-25T20:22:00.432184Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "   Cluster                                          Top Words\n0        0  [quiero, si, amor, voy, vos, vez, hoy, you, si...\n1        1  [si, pa, voy, bien, siempre, yeah, va, ahora, ...\n2        2  [si, voy, you, va, quiero, siempre, sÃ©, ey, so...\n3        3  [si, amor, quiero, voy, vos, hoy, siempre, tie...\n4        4  [um, nÃ£o, em, uma, do, com, mais, as, ao, da, ...\n5        5  [si, vida, amor, ser, siempre, tiempo, hoy, yo...\n6        6  [khalil, amia, irÃ¡n, iranÃ­es, delÃ­a, iranÃ­, me...\n7        7  [quiero, si, voy, amor, va, puede, tiempo, oh,...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cluster</th>\n      <th>Top Words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>[quiero, si, amor, voy, vos, vez, hoy, you, si...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[si, pa, voy, bien, siempre, yeah, va, ahora, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>[si, voy, you, va, quiero, siempre, sÃ©, ey, so...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>[si, amor, quiero, voy, vos, hoy, siempre, tie...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>[um, nÃ£o, em, uma, do, com, mais, as, ao, da, ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>[si, vida, amor, ser, siempre, tiempo, hoy, yo...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>[khalil, amia, irÃ¡n, iranÃ­es, delÃ­a, iranÃ­, me...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>[quiero, si, voy, amor, va, puede, tiempo, oh,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Step 1: Create a TfidfVectorizer instance\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Step 2: Fit the vectorizer on the cluster documents\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['Lyrics'])\n",
    "\n",
    "# Step 3: Get feature names (words) and cluster-based TF-IDF values\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Step 4: Create a DataFrame to store cluster-based TF-IDF values\n",
    "tfidf_df = pd.DataFrame(data=tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "# Step 5: Find the most important words per cluster (top N words for each cluster)\n",
    "num_top_words = 20  # You can change this number based on how many top words you want to extract per cluster\n",
    "\n",
    "cluster_representations = []\n",
    "\n",
    "for cluster_idx in df['Cluster_Labels'].unique():\n",
    "    cluster_rows = df[df['Cluster_Labels'] == cluster_idx]\n",
    "    cluster_tfidf_scores = tfidf_df.loc[cluster_rows.index].mean()  # Get mean TF-IDF scores for the current cluster\n",
    "    top_words_idx = cluster_tfidf_scores.argsort()[-num_top_words:][::-1]  # Get indices of top N words\n",
    "    top_words = [feature_names[idx] for idx in top_words_idx]  # Get actual words using indices\n",
    "    cluster_representations.append({\n",
    "        \"Cluster\": cluster_idx,\n",
    "        \"Top Words\": top_words\n",
    "    })\n",
    "\n",
    "pd.DataFrame(cluster_representations)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:22:01.772183300Z",
     "start_time": "2023-10-25T20:22:00.678184200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:22:01.845183Z",
     "start_time": "2023-10-25T20:22:01.789182Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
