{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:21:49.137425200Z",
     "start_time": "2023-10-25T20:21:42.282262100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1         2         3         4         5         6  \\\n0  0.285478 -0.267780  0.419370 -0.498186  0.542660  0.023841 -0.413265   \n1  0.005152 -0.338731  0.156136 -0.549878  0.695794  0.311146 -0.125933   \n2  0.116819 -0.197075  0.522070 -0.512381  0.799792  0.214954 -0.282300   \n3  0.064937 -0.105588  0.331254 -0.469864  0.336095  0.206220 -0.359127   \n4  0.100418 -0.234218  0.355078 -0.581577  0.777377  0.154805 -0.313815   \n\n          7         8         9  ...       759       760       761       762  \\\n0 -0.031106  0.037016 -0.089733  ...  0.053731 -0.071965 -0.196012 -0.272531   \n1 -0.057170 -0.142586 -0.237876  ...  0.050056 -0.013978 -0.242019 -0.162937   \n2  0.112953 -0.276646 -0.476294  ... -0.097296 -0.053955 -0.135379 -0.325609   \n3 -0.268113  0.054264 -0.154883  ...  0.032132 -0.176046 -0.018010 -0.372751   \n4  0.036311 -0.163821 -0.168941  ... -0.000433 -0.007743 -0.323721 -0.179224   \n\n        763       764       765       766       767                Track_ID  \n0 -0.218975  0.226477 -0.190769  0.270417 -0.245182  3oqWr0jDWNXxWufNogGREp  \n1 -0.217069  0.228585 -0.211428  0.152560 -0.290909  6gwaa6ElIixNTvu6RwkMyo  \n2 -0.221731  0.388578  0.004549  0.260015 -0.495187  1rh4kDY9T4fHVDum8Foi5k  \n3 -0.036383  0.301428 -0.064544  0.210582 -0.569920  12uaDRCVrgu4O6AyOZLrxG  \n4 -0.251005  0.338842 -0.198423  0.395761 -0.336876  17eJyYLIlMNlOqcwHYJ9F2  \n\n[5 rows x 769 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>759</th>\n      <th>760</th>\n      <th>761</th>\n      <th>762</th>\n      <th>763</th>\n      <th>764</th>\n      <th>765</th>\n      <th>766</th>\n      <th>767</th>\n      <th>Track_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.285478</td>\n      <td>-0.267780</td>\n      <td>0.419370</td>\n      <td>-0.498186</td>\n      <td>0.542660</td>\n      <td>0.023841</td>\n      <td>-0.413265</td>\n      <td>-0.031106</td>\n      <td>0.037016</td>\n      <td>-0.089733</td>\n      <td>...</td>\n      <td>0.053731</td>\n      <td>-0.071965</td>\n      <td>-0.196012</td>\n      <td>-0.272531</td>\n      <td>-0.218975</td>\n      <td>0.226477</td>\n      <td>-0.190769</td>\n      <td>0.270417</td>\n      <td>-0.245182</td>\n      <td>3oqWr0jDWNXxWufNogGREp</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.005152</td>\n      <td>-0.338731</td>\n      <td>0.156136</td>\n      <td>-0.549878</td>\n      <td>0.695794</td>\n      <td>0.311146</td>\n      <td>-0.125933</td>\n      <td>-0.057170</td>\n      <td>-0.142586</td>\n      <td>-0.237876</td>\n      <td>...</td>\n      <td>0.050056</td>\n      <td>-0.013978</td>\n      <td>-0.242019</td>\n      <td>-0.162937</td>\n      <td>-0.217069</td>\n      <td>0.228585</td>\n      <td>-0.211428</td>\n      <td>0.152560</td>\n      <td>-0.290909</td>\n      <td>6gwaa6ElIixNTvu6RwkMyo</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.116819</td>\n      <td>-0.197075</td>\n      <td>0.522070</td>\n      <td>-0.512381</td>\n      <td>0.799792</td>\n      <td>0.214954</td>\n      <td>-0.282300</td>\n      <td>0.112953</td>\n      <td>-0.276646</td>\n      <td>-0.476294</td>\n      <td>...</td>\n      <td>-0.097296</td>\n      <td>-0.053955</td>\n      <td>-0.135379</td>\n      <td>-0.325609</td>\n      <td>-0.221731</td>\n      <td>0.388578</td>\n      <td>0.004549</td>\n      <td>0.260015</td>\n      <td>-0.495187</td>\n      <td>1rh4kDY9T4fHVDum8Foi5k</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.064937</td>\n      <td>-0.105588</td>\n      <td>0.331254</td>\n      <td>-0.469864</td>\n      <td>0.336095</td>\n      <td>0.206220</td>\n      <td>-0.359127</td>\n      <td>-0.268113</td>\n      <td>0.054264</td>\n      <td>-0.154883</td>\n      <td>...</td>\n      <td>0.032132</td>\n      <td>-0.176046</td>\n      <td>-0.018010</td>\n      <td>-0.372751</td>\n      <td>-0.036383</td>\n      <td>0.301428</td>\n      <td>-0.064544</td>\n      <td>0.210582</td>\n      <td>-0.569920</td>\n      <td>12uaDRCVrgu4O6AyOZLrxG</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.100418</td>\n      <td>-0.234218</td>\n      <td>0.355078</td>\n      <td>-0.581577</td>\n      <td>0.777377</td>\n      <td>0.154805</td>\n      <td>-0.313815</td>\n      <td>0.036311</td>\n      <td>-0.163821</td>\n      <td>-0.168941</td>\n      <td>...</td>\n      <td>-0.000433</td>\n      <td>-0.007743</td>\n      <td>-0.323721</td>\n      <td>-0.179224</td>\n      <td>-0.251005</td>\n      <td>0.338842</td>\n      <td>-0.198423</td>\n      <td>0.395761</td>\n      <td>-0.336876</td>\n      <td>17eJyYLIlMNlOqcwHYJ9F2</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 769 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "## Cargo los embeddings\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "parquet_file_path = r'C:\\Users\\nunez\\Facultad\\Factor Data\\Embeddings\\clean_rock_nacional_w_embeddings.parquet'\n",
    "\n",
    "columns_to_load = [\"sentence_embeddings\", \"Track_ID\"]\n",
    "table = pq.read_table(parquet_file_path, columns=columns_to_load)\n",
    "df = table.to_pandas()\n",
    "del table\n",
    "df_1 = pd.DataFrame(df['sentence_embeddings'].to_list())\n",
    "df_2 = df[\"Track_ID\"]\n",
    "del df\n",
    "\n",
    "df = pd.concat([df_1, df_2], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aplico dimensionality reduction a los embeddings\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "pca = PCA(n_components=3)\n",
    "reduced_embeddings = pca.fit_transform(df.drop(columns=[\"Track_ID\"]))\n",
    "reduced_embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 2], reduced_embeddings[:, 1])\n",
    "\n",
    "ax.set_xlabel('PCA 1')\n",
    "ax.set_ylabel('PCA 2')\n",
    "ax.set_zlabel('PCA 3')\n",
    "plt.title('3D Scatter Plot Embeddings')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nunez\\Work\\DataSpell\\Venvs\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Cluster_Labels                Track_ID\n0                  3  3oqWr0jDWNXxWufNogGREp\n1                  3  6gwaa6ElIixNTvu6RwkMyo\n2                  5  1rh4kDY9T4fHVDum8Foi5k\n3                  3  12uaDRCVrgu4O6AyOZLrxG\n4                  3  17eJyYLIlMNlOqcwHYJ9F2\n...              ...                     ...\n2360               3  2MoFgRCvQMBy6cgw55oQvV\n2361               7  2axmxXWKBu2zEa1d8hrQVD\n2362               1  49bT0U3Ug059MXsBYrUWda\n2363               1  6RcII8epzXd254KF82RhAp\n2364               1  2A4A4iW4B3yoxkrgfXqtec\n\n[2365 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cluster_Labels</th>\n      <th>Track_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>3oqWr0jDWNXxWufNogGREp</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>6gwaa6ElIixNTvu6RwkMyo</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>1rh4kDY9T4fHVDum8Foi5k</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>12uaDRCVrgu4O6AyOZLrxG</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>17eJyYLIlMNlOqcwHYJ9F2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2360</th>\n      <td>3</td>\n      <td>2MoFgRCvQMBy6cgw55oQvV</td>\n    </tr>\n    <tr>\n      <th>2361</th>\n      <td>7</td>\n      <td>2axmxXWKBu2zEa1d8hrQVD</td>\n    </tr>\n    <tr>\n      <th>2362</th>\n      <td>1</td>\n      <td>49bT0U3Ug059MXsBYrUWda</td>\n    </tr>\n    <tr>\n      <th>2363</th>\n      <td>1</td>\n      <td>6RcII8epzXd254KF82RhAp</td>\n    </tr>\n    <tr>\n      <th>2364</th>\n      <td>1</td>\n      <td>2A4A4iW4B3yoxkrgfXqtec</td>\n    </tr>\n  </tbody>\n</table>\n<p>2365 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 8\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(df.drop(columns=[\"Track_ID\"]))\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "df = pd.concat([pd.Series(cluster_labels, name='Cluster_Labels'), df[\"Track_ID\"]],\n",
    "             axis=1)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:21:50.317425800Z",
     "start_time": "2023-10-25T20:21:49.136424500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "# Create a 3D scatter plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Iterate through clusters and plot data points with corresponding colors\n",
    "for cluster_label in df['Cluster_Labels'].unique():\n",
    "    mask = df[df[\"Cluster_Labels\"] == cluster_label]\n",
    "    ax.scatter(mask[0], mask[2], mask[1], label=f'Cluster {cluster_label}', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "plt.title('3D Scatter Plot of Embeddings with Cluster Colors')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "      Cluster_Labels                Track_ID  Unnamed: 0          Artist  \\\n0                  3  3oqWr0jDWNXxWufNogGREp           0  Gustavo Cerati   \n1                  3  6gwaa6ElIixNTvu6RwkMyo           0  Gustavo Cerati   \n2                  5  1rh4kDY9T4fHVDum8Foi5k           0  Gustavo Cerati   \n3                  3  12uaDRCVrgu4O6AyOZLrxG           0  Gustavo Cerati   \n4                  3  17eJyYLIlMNlOqcwHYJ9F2           0  Gustavo Cerati   \n...              ...                     ...         ...             ...   \n2496               3  2MoFgRCvQMBy6cgw55oQvV          86     Dread Mar I   \n2497               7  2axmxXWKBu2zEa1d8hrQVD          86     Dread Mar I   \n2498               1  49bT0U3Ug059MXsBYrUWda          86     Dread Mar I   \n2499               1  6RcII8epzXd254KF82RhAp          86     Dread Mar I   \n2500               1  2A4A4iW4B3yoxkrgfXqtec          86     Dread Mar I   \n\n                   Artist_ID  \\\n0     1QOmebWGB6FdFtW7Bo3F0W   \n1     1QOmebWGB6FdFtW7Bo3F0W   \n2     1QOmebWGB6FdFtW7Bo3F0W   \n3     1QOmebWGB6FdFtW7Bo3F0W   \n4     1QOmebWGB6FdFtW7Bo3F0W   \n...                      ...   \n2496  1aw0Cdl1DIrtUrUA6fGbAR   \n2497  1aw0Cdl1DIrtUrUA6fGbAR   \n2498  1aw0Cdl1DIrtUrUA6fGbAR   \n2499  1aw0Cdl1DIrtUrUA6fGbAR   \n2500  1aw0Cdl1DIrtUrUA6fGbAR   \n\n                                          Artist_genres  Artist_popularity  \\\n0     ['argentine rock', 'latin alternative', 'latin...                 70   \n1     ['argentine rock', 'latin alternative', 'latin...                 70   \n2     ['argentine rock', 'latin alternative', 'latin...                 70   \n3     ['argentine rock', 'latin alternative', 'latin...                 70   \n4     ['argentine rock', 'latin alternative', 'latin...                 70   \n...                                                 ...                ...   \n2496  ['argentine reggae', 'latin alternative', 'roc...                 69   \n2497  ['argentine reggae', 'latin alternative', 'roc...                 69   \n2498  ['argentine reggae', 'latin alternative', 'roc...                 69   \n2499  ['argentine reggae', 'latin alternative', 'roc...                 69   \n2500  ['argentine reggae', 'latin alternative', 'roc...                 69   \n\n                    Track Track_release_date  Track_popularity  \\\n0                  Crimen         2006-04-04              75.0   \n1                  Puente         1999-06-01              71.0   \n2                   Adiós         2006-04-04              73.0   \n3                Bocanada         1999-06-01              64.0   \n4        Lago en el Cielo         2006-04-04              68.0   \n...                   ...                ...               ...   \n2496           Tu Soldado         2012-11-01              48.0   \n2497            La Suerte         2018-05-18              48.0   \n2498    Sálvame - En Vivo         2016-05-06              47.0   \n2499  Tu Sin Mi - En Vivo         2016-05-06              45.0   \n2500    Mi Amor - En Vivo         2016-05-06              46.0   \n\n                                                 Lyrics  \\\n0        la espera me agotó no sé nada de vos dejast...   \n1        hoy te busqué en la rima que duerme con tod...   \n2        suspiraban lo mismo los dos y hoy son parte...   \n3        cuando no hay más que decirnos habla el hum...   \n4        un lago en el cielo quiero ser suave para e...   \n...                                                 ...   \n2496    oh sí hoy me quieren convencer para que caig...   \n2497  letra de la suerte   la suerte que tú creas na...   \n2498   lyrics te convertí en una reina pa cualquier ...   \n2499     yeah yeah yeah vine a romper un beat que pu...   \n2500     me gustas tú me gusta la lluvia me gustas t...   \n\n                                          features_dict  \n0                                                   NaN  \n1                                                   NaN  \n2     {'danceability': 0.495, 'energy': 0.596, 'key'...  \n3     {'danceability': 0.47, 'energy': 0.575, 'key':...  \n4     {'danceability': 0.539, 'energy': 0.833, 'key'...  \n...                                                 ...  \n2496  {'danceability': 0.699, 'energy': 0.271, 'key'...  \n2497  {'danceability': 0.687, 'energy': 0.614, 'key'...  \n2498  {'danceability': 0.562, 'energy': 0.742, 'key'...  \n2499  {'danceability': 0.578, 'energy': 0.689, 'key'...  \n2500  {'danceability': 0.372, 'energy': 0.672, 'key'...  \n\n[2265 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cluster_Labels</th>\n      <th>Track_ID</th>\n      <th>Unnamed: 0</th>\n      <th>Artist</th>\n      <th>Artist_ID</th>\n      <th>Artist_genres</th>\n      <th>Artist_popularity</th>\n      <th>Track</th>\n      <th>Track_release_date</th>\n      <th>Track_popularity</th>\n      <th>Lyrics</th>\n      <th>features_dict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>3oqWr0jDWNXxWufNogGREp</td>\n      <td>0</td>\n      <td>Gustavo Cerati</td>\n      <td>1QOmebWGB6FdFtW7Bo3F0W</td>\n      <td>['argentine rock', 'latin alternative', 'latin...</td>\n      <td>70</td>\n      <td>Crimen</td>\n      <td>2006-04-04</td>\n      <td>75.0</td>\n      <td>la espera me agotó no sé nada de vos dejast...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>6gwaa6ElIixNTvu6RwkMyo</td>\n      <td>0</td>\n      <td>Gustavo Cerati</td>\n      <td>1QOmebWGB6FdFtW7Bo3F0W</td>\n      <td>['argentine rock', 'latin alternative', 'latin...</td>\n      <td>70</td>\n      <td>Puente</td>\n      <td>1999-06-01</td>\n      <td>71.0</td>\n      <td>hoy te busqué en la rima que duerme con tod...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>1rh4kDY9T4fHVDum8Foi5k</td>\n      <td>0</td>\n      <td>Gustavo Cerati</td>\n      <td>1QOmebWGB6FdFtW7Bo3F0W</td>\n      <td>['argentine rock', 'latin alternative', 'latin...</td>\n      <td>70</td>\n      <td>Adiós</td>\n      <td>2006-04-04</td>\n      <td>73.0</td>\n      <td>suspiraban lo mismo los dos y hoy son parte...</td>\n      <td>{'danceability': 0.495, 'energy': 0.596, 'key'...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>12uaDRCVrgu4O6AyOZLrxG</td>\n      <td>0</td>\n      <td>Gustavo Cerati</td>\n      <td>1QOmebWGB6FdFtW7Bo3F0W</td>\n      <td>['argentine rock', 'latin alternative', 'latin...</td>\n      <td>70</td>\n      <td>Bocanada</td>\n      <td>1999-06-01</td>\n      <td>64.0</td>\n      <td>cuando no hay más que decirnos habla el hum...</td>\n      <td>{'danceability': 0.47, 'energy': 0.575, 'key':...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>17eJyYLIlMNlOqcwHYJ9F2</td>\n      <td>0</td>\n      <td>Gustavo Cerati</td>\n      <td>1QOmebWGB6FdFtW7Bo3F0W</td>\n      <td>['argentine rock', 'latin alternative', 'latin...</td>\n      <td>70</td>\n      <td>Lago en el Cielo</td>\n      <td>2006-04-04</td>\n      <td>68.0</td>\n      <td>un lago en el cielo quiero ser suave para e...</td>\n      <td>{'danceability': 0.539, 'energy': 0.833, 'key'...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2496</th>\n      <td>3</td>\n      <td>2MoFgRCvQMBy6cgw55oQvV</td>\n      <td>86</td>\n      <td>Dread Mar I</td>\n      <td>1aw0Cdl1DIrtUrUA6fGbAR</td>\n      <td>['argentine reggae', 'latin alternative', 'roc...</td>\n      <td>69</td>\n      <td>Tu Soldado</td>\n      <td>2012-11-01</td>\n      <td>48.0</td>\n      <td>oh sí hoy me quieren convencer para que caig...</td>\n      <td>{'danceability': 0.699, 'energy': 0.271, 'key'...</td>\n    </tr>\n    <tr>\n      <th>2497</th>\n      <td>7</td>\n      <td>2axmxXWKBu2zEa1d8hrQVD</td>\n      <td>86</td>\n      <td>Dread Mar I</td>\n      <td>1aw0Cdl1DIrtUrUA6fGbAR</td>\n      <td>['argentine reggae', 'latin alternative', 'roc...</td>\n      <td>69</td>\n      <td>La Suerte</td>\n      <td>2018-05-18</td>\n      <td>48.0</td>\n      <td>letra de la suerte   la suerte que tú creas na...</td>\n      <td>{'danceability': 0.687, 'energy': 0.614, 'key'...</td>\n    </tr>\n    <tr>\n      <th>2498</th>\n      <td>1</td>\n      <td>49bT0U3Ug059MXsBYrUWda</td>\n      <td>86</td>\n      <td>Dread Mar I</td>\n      <td>1aw0Cdl1DIrtUrUA6fGbAR</td>\n      <td>['argentine reggae', 'latin alternative', 'roc...</td>\n      <td>69</td>\n      <td>Sálvame - En Vivo</td>\n      <td>2016-05-06</td>\n      <td>47.0</td>\n      <td>lyrics te convertí en una reina pa cualquier ...</td>\n      <td>{'danceability': 0.562, 'energy': 0.742, 'key'...</td>\n    </tr>\n    <tr>\n      <th>2499</th>\n      <td>1</td>\n      <td>6RcII8epzXd254KF82RhAp</td>\n      <td>86</td>\n      <td>Dread Mar I</td>\n      <td>1aw0Cdl1DIrtUrUA6fGbAR</td>\n      <td>['argentine reggae', 'latin alternative', 'roc...</td>\n      <td>69</td>\n      <td>Tu Sin Mi - En Vivo</td>\n      <td>2016-05-06</td>\n      <td>45.0</td>\n      <td>yeah yeah yeah vine a romper un beat que pu...</td>\n      <td>{'danceability': 0.578, 'energy': 0.689, 'key'...</td>\n    </tr>\n    <tr>\n      <th>2500</th>\n      <td>1</td>\n      <td>2A4A4iW4B3yoxkrgfXqtec</td>\n      <td>86</td>\n      <td>Dread Mar I</td>\n      <td>1aw0Cdl1DIrtUrUA6fGbAR</td>\n      <td>['argentine reggae', 'latin alternative', 'roc...</td>\n      <td>69</td>\n      <td>Mi Amor - En Vivo</td>\n      <td>2016-05-06</td>\n      <td>46.0</td>\n      <td>me gustas tú me gusta la lluvia me gustas t...</td>\n      <td>{'danceability': 0.372, 'energy': 0.672, 'key'...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2265 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "df1 = pd.read_csv(r\"C:\\Users\\nunez\\Facultad\\Factor Data\\Proyecto NLP canciones\\Datasets Scrapeados\\Rock_Nacional.csv\")\n",
    "df = pd.merge(df,df1,on=\"Track_ID\")\n",
    "df\n",
    "\n",
    "\n",
    "## Cleansing\n",
    "df.dropna(subset=\"Lyrics\",inplace=True)\n",
    "def clean(text):\n",
    "    cleaned_text = re.sub(r\"^.*?Lyrics\", \"\", text)\n",
    "    cleaned_text = re.sub(r'\\[.*?\\]', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\([^)]*\\)', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\\\n', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\n', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'Embed', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'you might also like', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'you', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'might', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'also', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'like', '', cleaned_text)\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return cleaned_text\n",
    "\n",
    "df[\"Lyrics\"] = df[\"Lyrics\"].astype(str).apply(clean)\n",
    "df[\"Artist_genres\"] = df[\"Artist_genres\"].replace(\"[]\",np.nan)\n",
    "df.dropna(subset=\"Artist_genres\",inplace=True)\n",
    "df = df.drop_duplicates(subset=[\"Lyrics\",\"Artist_ID\",\"Track\"])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:21:51.826426Z",
     "start_time": "2023-10-25T20:21:50.321424400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = df.groupby(\"Cluster_Labels\")[\"Lyrics\"].apply(lambda x: ' '.join(x)).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:21:51.842425200Z",
     "start_time": "2023-10-25T20:21:51.828425900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   Cluster_Labels                                             Lyrics\n0               0     un cactus suaviza mis yemas con su piel tie...\n1               1  en la mañana desayuno las dudas que sobran de ...\n2               2     ya no me necesitas es lo mejor eras alguien...\n3               3     la espera me agotó no sé nada de vos dejast...\n4               4  os sertões de euclides da cunha fonte cunha eu...\n5               5     suspiraban lo mismo los dos y hoy son parte...\n6               6   erasmo de rotterda lyricsenquiridion o manual...\n7               7  no me arrepiento de este amor aunque me cueste...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cluster_Labels</th>\n      <th>Lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>un cactus suaviza mis yemas con su piel tie...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>en la mañana desayuno las dudas que sobran de ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>ya no me necesitas es lo mejor eras alguien...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>la espera me agotó no sé nada de vos dejast...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>os sertões de euclides da cunha fonte cunha eu...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>suspiraban lo mismo los dos y hoy son parte...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>erasmo de rotterda lyricsenquiridion o manual...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>no me arrepiento de este amor aunque me cueste...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:21:51.978426400Z",
     "start_time": "2023-10-25T20:21:51.842425200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download necessary NLTK resources if you haven't already\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load Spanish stopwords\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "# Define the function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    words = nltk.word_tokenize(text, language='spanish')\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "\n",
    "# Assuming df is your DataFrame and \"Lyrics\" is the column containing text data\n",
    "df[\"Lyrics\"] = df[\"Lyrics\"].apply(remove_stopwords)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:22:00.431182400Z",
     "start_time": "2023-10-25T20:21:51.942424800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   Cluster_Labels                                             Lyrics\n0               0  cactus suaviza yemas piel cien años solo flore...\n1               1  mañana desayuno dudas sobran noche anterior lu...\n2               2  necesitas mejor alguien quién solía conocer si...\n3               3  espera agotó sé vos dejaste llamas acosté lent...\n4               4  sertões euclides da cunha fonte cunha euclides...\n5               5  suspiraban mismo dos hoy parte lluvia lejos co...\n6               6  erasmo rotterda lyricsenquiridion manual cabal...\n7               7  arrepiento amor aunque cueste corazón amar mil...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cluster_Labels</th>\n      <th>Lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>cactus suaviza yemas piel cien años solo flore...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>mañana desayuno dudas sobran noche anterior lu...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>necesitas mejor alguien quién solía conocer si...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>espera agotó sé vos dejaste llamas acosté lent...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>sertões euclides da cunha fonte cunha euclides...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>suspiraban mismo dos hoy parte lluvia lejos co...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>erasmo rotterda lyricsenquiridion manual cabal...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>arrepiento amor aunque cueste corazón amar mil...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:22:00.479183400Z",
     "start_time": "2023-10-25T20:22:00.432184Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "   Cluster                                          Top Words\n0        0  [quiero, si, amor, voy, vos, vez, hoy, you, si...\n1        1  [si, pa, voy, bien, siempre, yeah, va, ahora, ...\n2        2  [si, voy, you, va, quiero, siempre, sé, ey, so...\n3        3  [si, amor, quiero, voy, vos, hoy, siempre, tie...\n4        4  [um, não, em, uma, do, com, mais, as, ao, da, ...\n5        5  [si, vida, amor, ser, siempre, tiempo, hoy, yo...\n6        6  [khalil, amia, irán, iraníes, delía, iraní, me...\n7        7  [quiero, si, voy, amor, va, puede, tiempo, oh,...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cluster</th>\n      <th>Top Words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>[quiero, si, amor, voy, vos, vez, hoy, you, si...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[si, pa, voy, bien, siempre, yeah, va, ahora, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>[si, voy, you, va, quiero, siempre, sé, ey, so...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>[si, amor, quiero, voy, vos, hoy, siempre, tie...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>[um, não, em, uma, do, com, mais, as, ao, da, ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>[si, vida, amor, ser, siempre, tiempo, hoy, yo...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>[khalil, amia, irán, iraníes, delía, iraní, me...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>[quiero, si, voy, amor, va, puede, tiempo, oh,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Step 1: Create a TfidfVectorizer instance\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Step 2: Fit the vectorizer on the cluster documents\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['Lyrics'])\n",
    "\n",
    "# Step 3: Get feature names (words) and cluster-based TF-IDF values\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Step 4: Create a DataFrame to store cluster-based TF-IDF values\n",
    "tfidf_df = pd.DataFrame(data=tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "# Step 5: Find the most important words per cluster (top N words for each cluster)\n",
    "num_top_words = 20  # You can change this number based on how many top words you want to extract per cluster\n",
    "\n",
    "cluster_representations = []\n",
    "\n",
    "for cluster_idx in df['Cluster_Labels'].unique():\n",
    "    cluster_rows = df[df['Cluster_Labels'] == cluster_idx]\n",
    "    cluster_tfidf_scores = tfidf_df.loc[cluster_rows.index].mean()  # Get mean TF-IDF scores for the current cluster\n",
    "    top_words_idx = cluster_tfidf_scores.argsort()[-num_top_words:][::-1]  # Get indices of top N words\n",
    "    top_words = [feature_names[idx] for idx in top_words_idx]  # Get actual words using indices\n",
    "    cluster_representations.append({\n",
    "        \"Cluster\": cluster_idx,\n",
    "        \"Top Words\": top_words\n",
    "    })\n",
    "\n",
    "pd.DataFrame(cluster_representations)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:22:01.772183300Z",
     "start_time": "2023-10-25T20:22:00.678184200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T20:22:01.845183Z",
     "start_time": "2023-10-25T20:22:01.789182Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
